---
layout: archive
---

<h2>About me</h2>
<p> I am currently a PhD student in College of AI, Tsinghua University, supervised by <a href="https://lumimim.github.io/">Lu Mi</a>. 
    I have received my Bachelor's degree and Master's degree in 2022 and 2025, respectively, from School of Computer Science and Engineering, Beihang University.</p>
<p>My current research interests include <strong>AI + Cognitive Science & AI + Education</strong>.</p>
<p>I am an &quot;advocate&quot; (INFJ) person, idealistic, passionate about life, enthusiastic about scientific research. 
    I always want to get rid of the appearance of things to get to the essence, and devote the full of myself to it.</p>
<h2>Education</h2>
<ul>
<li>PhD, College of AI, Tsinghua University, 2025.9~present</li>
<li>Master, School of Computer Science and Engineering, Beihang University, 2022.9~2025.6</li>
<li>Bachelor, School of Computer Science and Engineering, Beihang University, 2018.9~2022.6</li>
<li>Language: IELTS 7.5</li>
</ul>

<h2>
    Research
</h2>

<!-- here is the table of my papers, two columns, left is the picture, right is the title followed by a link icon, authors in new line, published date & conference in new line, TLDR in new line-->
<table>
<!-- complete the table with your own papers, pictures need to be smaller -->
<tr>
    <td style="width: 200px;">
        <img src="/assets/images/StudentSim.png" alt="llm_student_simulation" sizes="(max-width: 200px)">
    </td>
    <td>
        <a href="https://arxiv.org/abs/2502.11678">Exploring LLM-based Student Simulation for Metacognitive Cultivation</a>
        <br>
        <strong>Haoxuan Li</strong>, Jifan Yu, Xin Cong, Yang Dang, Yisi Zhan, Huiqin Liu, Zhiyuan Liu
        <br>
        <i>arxiv preprint, 2025</i>
        <br>
        <p>This work proposes a pipeline to simulate students with learning difficulties using LLMs, supporting metacognitive training through scalable and explainable agents evaluated via a score propagation system.</p>
    </td>
</tr>
<tr>
    <td style="width: 200px;">
        <img src="/assets/images/LecEval.png" alt="leceval_multimodal_learning" sizes="(max-width: 200px)">
    </td>
    <td>
        <a href="https://arxiv.org/abs/2505.02078">LecEval: An Automated Metric for Multimodal Knowledge Acquisition in Multimedia Learning</a>
        <br>
        Joy Lim Jia Yin, Daniel Zhang-Li, Jifan Yu, <strong>Haoxuan Li</strong>, Shangqing Tu, Yuanchun Wang, Zhiyuan Liu, Huiqin Liu, Lei Hou, Juanzi Li, Bin Xu
        <br>
        <i>arxiv preprint, 2025</i>
        <br>
        <p>We introduce LecEval, a novel metric grounded in multimedia learning theory for automatically evaluating knowledge acquisition in slide-based educational content using four pedagogical rubrics.</p>
    </td>
</tr>
<tr>
    <td style="width: 200px;">
        <img src="/assets/images/MAIC.png" alt="mooc_to_maic" sizes="(max-width: 200px)">
    </td>
    <td>
        <a href="https://arxiv.org/abs/2409.03512">From MOOC to MAIC: Reshaping Online Teaching and Learning through LLM-driven Agents</a>
        <br>
        Jifan Yu, Zheyuan Zhang, Daniel Zhang-Li, Shangqing Tu, Zhanxin Hao, Ruimiao Li, <strong>Haoxuan Li</strong>, Yuanchun Wang, Hanming Li, Linlu Gong, Jie Cao, Jiayin Lin, Jinchang Zhou, Fei Qin, Haohua Wang, Jianxiao Jiang, Lijun Deng, Yisi Zhan, Chaojun Xiao, Xusheng Dai, Xuan Yan, Nianyi Lin, Nan Zhang, Ruixin Ni, Yang Dang, Lei Hou, Yu Zhang, Xu Han, Manli Li, Juanzi Li, Zhiyuan Liu, Huiqin Liu, Maosong Sun
        <br>
        <i>arxiv preprint, 2024</i>
        <br>
        <p>We propose MAIC, a scalable and adaptive LLM-based multi-agent framework for personalized online education, validated on 100K learning records and designed as a future collaborative open platform.</p>
    </td>
</tr>
<tr>
    <td style="width: 200px;">
        <img src="/assets/images/EFKT.png" alt="explainable_fewshot_knowledge_tracing" sizes="(max-width: 200px)">
    </td>
    <!-- The column below  -->
    <td>
        <a href="https://arxiv.org/abs/2405.14391">Explainable Few-shot Knowledge Tracing</a>
        <br>
        <!-- Haoxuan Li need to be bold -->
        <strong>Haoxuan Li</strong>, Jifan Yu, Yuanxin Ouyang, Zhuang Liu, Wenge Rong, Juanzi Li, Zhang Xiong
        <br>
        <i>arxiv preprint, 2024</i>
        <br>
        <p>We introduce Explainable Few-shot Knowledge Tracing, a new educational assessment method using large language models to predict student knowledge from limited data with natural language explanations.</p>
    </td>
</tr>
<tr>
    <td style="width: 200px;">
        <img src="/assets/images/WGAT.png" alt="wasserstein_dependent_graph_attention_network" sizes="(max-width: 200px)">
    </td>
    <td>
        <a href="https://ieeexplore.ieee.org/abstract/document/10601643/">Wasserstein Dependent Graph Attention Network for Collaborative Filtering with Uncertainty</a>
        <br>
        <strong>Haoxuan Li</strong>, Yuanxin Ouyang, Zhuang Liu, Wenge Rong, Zhang Xiong
        <br>
        <i>IEEE Transactions on Computational Scoial Systems, 2024</i>
        <br>
        <p>W-GAT is a novel graph attention network for collabohrative filtering that uses Wasserstein distance to capture user and item uncertainty, improving recommendation accuracy.</p>
    </td>
</tr>
<tr>
    <td style="width: 200px;">
        <img src="/assets/images/PER.png" alt="PER" sizes="(max-width: 200px)">
    </td>
    <td>
        <a href="https://journal.hep.com.cn/fde/EN/10.3868/s110-009-024-0004-9">A Review of Data Mining in Personalized Education: Current Trends and Future Prospects</a>
        <br>
        Zhang Xiong, <strong>Haoxuan Li</strong>, Zhuang Liu, Zhuofan Chen, Hao Zhou, Wenge Rong, Yuanxin Ouyang
        <br>
        <i>Frontiers of Digital Education, 2024</i>
        <br>
        <p>We review data mining advancements in personalized education, covering educational recommendation, cognitive diagnosis, knowledge tracing, and learning analysis, providing structured taxonomies, datasets, and future research directions.</p>
    </td>
</tr>
<tr>
    <td style="width: 200px;">
        <img src="/assets/images/PopDCL.png" alt="PopDCL" sizes="(max-width: 200px)">
    </td>
    <td>
        <a href="https://dl.acm.org/doi/abs/10.1145/3583780.3615009">PopDCL: Popularity-aware Debiased Contrastive Loss for Collaborative Filtering</a>
        <br>
        Zhuang Liu, <strong>Haoxuan Li</strong>, Guanming Chen, Yuanxin Ouyang, Wenge Rong, Zhang Xiong
        <br>
        <i>CIKM 2023</i>
        <br>
        <p>We propose PopDCL, a novel contrastive learning framework for collaborative filtering that addresses the popularity bias and sample bias in recommendation systems.</p>
    </td>
</tr>
<tr>
    <td style="width: 200px;">
        <img src="/assets/images/DCL.png" alt="DCL" sizes="(max-width: 200px)">
    </td>
    <td>
        <a href="https://link.springer.com/chapter/10.1007/978-3-031-40289-0_8">Debiased Contrastive Loss for Collaborative Filtering</a>
        <br>
        Zhuang Liu, Yunpu Ma, <strong>Haoxuan Li</strong>, Marcel Hildebrandt, Yuanxin Ouyang, Zhang Xiong
        <br>
        <i>KSEM 2023</i>
        <br>
        <p>We introduce a debiased contrastive loss for collaborative filtering in recommender systems to correct sample bias, enhancing user interest representation. It's integrated into MF and GNN models, improving performance and training efficiency.</p>
    </td>
</tr>
</table>


<h2>Skills &amp; Languages</h2>
<ul>
<li>â˜…â˜…â˜… Python, Torch</li>
<li>â˜…â˜…â˜† Tensorflow</li>
<li>â˜…â˜…â˜† Java, C</li>

</ul>
<ul>
<li>â˜…â˜…â˜… Chinese</li>
<li>â˜…â˜…â˜† English</li>

</ul>
<h2>Hobbies</h2>
<ul>
<li>Addictive footballerâš½</li>
<li>PhotographyðŸ“·</li>
<li>CyclingðŸš²</li>

</ul>


{% include paginator.html %}